# ğŸ“š Notionary: AI-Powered Interactive Learning Assistant

## ğŸš€ Overview

**Notionary** is an advanced, AI-powered backend platform that empowers educators and students by enabling real-time, document-specific doubt resolution through LLMs and secure vector search. Built with **FastAPI**, **Ollama**, **Google Gemini** and **Supabase**, this system is designed to handle contextual Q\&A from uploaded PDFs with high precision and strict data isolation.

> "Notionary is not just an assistantâ€”it's your classroom companion, ensuring every student gets the help they need from the material they trust."
> 

## ğŸ’¡ Why Notionary Matters

Modern classrooms struggle with:

* â“ **Generic Responses** from traditional AI tools
* ğŸ§  **Information Overload**
* ğŸ” **Data Privacy Concerns**
* ğŸ§ª **Hallucinations** in AI answers

**Notionary solves these problems through:**

* ğŸ” Context-grounded answers using *only* user-uploaded content
* ğŸ§¬ Local embeddings via **Ollama** for performance and privacy
* ğŸ”’ **Row-Level Security (RLS)** in Supabase for strict user isolation
* ğŸ§  LLMs (Gemini) instructed with **strict prompting** to avoid hallucination

## ğŸŒŸ Key Features

### ğŸ“„ Document-Specific QA

* Ask questions about specific PDFs or search across all documents
* Get source-cited responses from the relevant page and file

### ğŸ¤– Local Embeddings (Ollama)

* 768-dimensional embeddings generated locally
* Fast and private with no cloud dependency

### ğŸ§  Gemini LLM Integration

* Accurate and concise answers
* Strict prompting to avoid general knowledge outside the document

### ğŸ¯ Smart Context Retrieval

* Embedding-based semantic search
* Custom similarity threshold and chunk filtering

### ğŸŒ Enhanced Web Interface

* Upload, manage and interact with PDFs in a modern UI
* PDF selector with real-time document status

### ğŸ“Š Processing Dashboard

* Track upload, embedding, and availability status

### ğŸ”’ Complete User Isolation

* Full RLS enforcement: each user sees only their own PDFs and data
* Secure authentication with Supabase JWT

### ğŸš« Strict Document-Only Mode

* If LLM finds no relevant context, it **refuses** to generate general knowledge
* Clear citation and reference model for transparency

## ğŸ Quick Start Guide

### âœ… Prerequisites

* Python 3.8+
* [Ollama](https://ollama.ai/download)
* [Supabase](https://supabase.com)
* Google Gemini API Key (free tier available)

### ğŸ”§ Installation Steps

#### 1. Install Ollama

```bash
# macOS
brew install ollama

# Windows
winget install ollama

# Linux
curl -fsSL https://ollama.ai/install.sh | sh
```

Start the Ollama service:

```bash
ollama serve
ollama pull nomic-embed-text
```

#### 2. Python Environment Setup

```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

#### 3. Configuration

Create a `.env` file:

```env
SUPABASE_URL=your_url
SUPABASE_KEY=your_anon_key
SUPABASE_SERVICE_KEY=your_service_key
GEMINI_API_KEY=your_gemini_key
DATABASE_URL=postgresql://... (optional)
```

#### 4. Start the Server

```bash
ollama serve
python run_server.py
```

Visit:

* ğŸŒ UI: `http://localhost:8000/frontend`
* ğŸ“š API Docs: `http://localhost:8000/docs`
* ğŸ’š Health: `http://localhost:8000/health`


## â“ How to Use

### ğŸ“¤ Upload PDFs

* Drag & drop files into the UI
* Embeddings are generated using Ollama
* Each file is user-scoped

### ğŸ’¬ Ask Questions

**Option A: Web UI**

* Select a document and type a query
* Get sourced answers

**Option B: API**

```bash
curl -X POST "http://localhost:8000/api/v1/ask" -H "Content-Type: application/json" -d '{"question": "What is X?", "document_id": "..."}'
```

### ğŸš« Strict Mode Example

> "Who is Ramanujan?" â†’ "The selected document does not contain information about Ramanujan."

## ğŸ§¬ Architecture

```
+------------+       REST        +-----------+
|  Frontend  | <---------------> |  FastAPI  |
+------------+                   +-----------+
                                  |   |   |
                             Embedding  LLM
                             (Ollama)  (Gemini)
                                  |
                            +-----------+
                            | Supabase  |
                            +-----------+
```

## ğŸ› ï¸ Project Structure

```
ai-tutor-backend/
â”œâ”€â”€ api/                      # FastAPI routes
â”œâ”€â”€ core/                     # DB + config
â”œâ”€â”€ modules/                  # PDF and AI logic
â”œâ”€â”€ frontend/                 # Static web interface
â”œâ”€â”€ tests/                    # Test suite
â”œâ”€â”€ run_server.py             # Entry point
â””â”€â”€ .env                      # Environment vars
```

## ğŸ§ª Test Coverage

* âœ… PDF Upload
* âœ… User RLS Enforcement
* âœ… Document-only LLM Answers
* âœ… No General Knowledge Leakage
* âœ… Chunk Filtering

Test scripts:

* `test_strict_document_mode.py`
* `test_subjects_endpoint.py`
* `debug_document_restriction.py`

## ğŸ“ˆ Scaling & Cost

* **Local Embeddings**: Free with Ollama
* **Gemini API**: Free tier (15 req/min)
* **Supabase Free Tier**: 500MB storage, 2GB bandwidth

Estimated Monthly Cost: `$0 â€“ $3` for moderate usage

## ğŸ”® Future Plans

* [ ] Mobile App
* [ ] Add Proctored Mode for examinations
* [ ] Analytics Dashboard
* [ ] Claude / GPT Integration
* [ ] Multi-language Support
* [ ] Teacher Dashboard

## ğŸ¤ Contributing

PRs are welcome! Please follow conventions, write clean code and add tests.

## ğŸ“¬ Contact

For support or feedback:

* Open an [issue](https://github.com/Aravind556/Intel/issues)
